{"extracted_information": "Detailed specifications, performance benchmarks, memory requirements, and technical details for the Llama 3.2 1B model are provided, including training data, quantization schemes, inference performance, and various benchmark scores across different tasks and languages. This model is part of a multilingual large language model collection, optimized for dialogue use cases.", "specifications": {"model_developer": "Meta", "model_architecture": "Auto-regressive language model, optimized transformer architecture. Tuned versions use Supervised Fine-Tuning (SFT) and Reinforcement Learning with Human Feedback (RLHF) for alignment.", "model_family": "Llama 3.2 collection of multilingual large language models (LLMs)", "sizes_available": ["1B (1.23B)", "3B (3.21B)"], "input_modalities": "Multilingual Text", "output_modalities": "Multilingual Text and code", "context_length": {"text_only": "128k", "quantized_text_only": "8k"}, "group_query_attention": "Yes", "shared_embeddings": "Yes", "token_count": "Up to 9T tokens (pretraining data only)", "supported_languages_officially": ["English", "German", "French", "Italian", "Portuguese", "Hindi", "Spanish", "Thai"], "status": "Static model trained on an offline dataset. Future versions may be released."}, "pricing": {}, "features": ["Optimized for multilingual dialogue use cases (instruction-tuned models)", "Agentic retrieval and summarization tasks", "Outperforms many available open-source and closed chat models on common industry benchmarks", "Uses Grouped-Query Attention (GQA) for improved inference scalability", "Pretrained models adaptable for various natural language generation tasks", "Quantized models adaptable for on-device use-cases with limited compute resources", "Multimodal models included in Llama 3.2 (with specific EU restrictions for individuals/companies)", "Supports use with Hugging Face transformers library (>= 4.43.0)", "Supports use with original `llama` codebase"], "statistics": {"training_energy_use": {"llama_3_2_1b_gpu_hours": "370k", "llama_3_2_3b_gpu_hours": "460k", "llama_3_2_1b_spinquant_gpu_hours": "1.7", "llama_3_2_3b_spinquant_gpu_hours": "2.4", "llama_3_2_1b_qlora_gpu_hours": "1.3k", "llama_3_2_3b_qlora_gpu_hours": "1.6k", "total_training_gpu_hours": "833k", "total_logit_generation_gpu_hours": "86k", "power_consumption_per_gpu": "700W (H100-80GB)", "hardware_type": "H100-80GB"}, "training_greenhouse_gas_emissions": {"llama_3_2_1b_location_based_co2eq": "107 tons", "llama_3_2_1b_market_based_co2eq": "0 tons", "llama_3_2_3b_location_based_co2eq": "133 tons", "llama_3_2_3b_market_based_co2eq": "0 tons", "llama_3_2_1b_spinquant_location_based_co2eq": "negligible (<0.001 metric tonnes)", "llama_3_2_1b_spinquant_market_based_co2eq": "0 tons", "llama_3_2_3b_spinquant_location_based_co2eq": "negligible (<0.001 metric tonnes)", "llama_3_2_3b_spinquant_market_based_co2eq": "0 tons", "llama_3_2_1b_qlora_location_based_co2eq": "0.381 tons", "llama_3_2_1b_qlora_market_based_co2eq": "0 tons", "llama_3_2_3b_qlora_location_based_co2eq": "0.461 tons", "llama_3_2_3b_qlora_market_based_co2eq": "0 tons", "total_location_based_co2eq": "240 tons", "total_market_based_co2eq": "0 tons (Meta maintains net zero greenhouse gas emissions and 100% renewable electricity)"}, "model_downloads_last_month": "2,545,110"}, "temporal_info": {"llama_3_2_version_release_date": "September 25, 2024", "model_release_date": "Sept 25, 2024", "knowledge_cutoff": "December 2023"}, "geographical_data": {}, "references": ["Meta Privacy Policy: https://www.facebook.com/privacy/policy/", "Llama 3.2 Community License: https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/LICENSE", "Acceptable Use Policy for the Llama Materials", "Meta’s brand guidelines", "Reporting issues with the model: https://github.com/meta-llama/llama-models/issues", "Reporting risky content generated by the model: developers.facebook.com/llama_output_feedback", "Reporting bugs and security concerns: facebook.com/whitehat/info", "Reporting violations of the Acceptable Use Policy or unlicensed uses of Llama 3.2: LlamaUseReport@meta.com", "Llama Models README: https://github.com/meta-llama/llama-models/blob/main/README.md", "Llama recipes (generation parameters and usage): https://github.com/meta-llama/llama-recipes", "PyTorch’s ExecuTorch: https://github.com/pytorch/executorch", "SpinQuant paper: https://arxiv.org/abs/2405.16406", "QLoRA (Dettmers et al., 2023)", "Methodology for training energy use and greenhouse gas emissions: https://arxiv.org/pdf/2204.05149", "Meta’s Llama models Community Stories webpage: https://llama.meta.com/community-stories/", "Responsible Use Guide: https://llama.meta.com/responsible-use-guide/", "Llama 3 paper: https://ai.meta.com/research/publications/the-llama-3-herd-of-models/", "Trust and Safety solutions: https://llama.meta.com/trust-and-safety/", "Reference implementations (llama-agentic-system): https://github.com/meta-llama/llama-agentic-system", "Llama 3.1 Model Card: https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md", "Purple Llama Github repository: https://github.com/meta-llama/PurpleLlama", "Llama Impact Grants program: https://llama.meta.com/llama-impact-grants/", "Llama Impact Grants finalists: https://llama.meta.com/llama-impact-grants/#finalists", "Other resources: https://llama.meta.com/docs/get-started/"], "technical_details": {"training_data_overview": "Pretrained on up to 9 trillion tokens from publicly available sources. Incorporates logits from Llama 3.1 8B and 70B models for knowledge distillation during pretraining. Post-training uses similar recipe as Llama 3.1: Supervised Fine-Tuning (SFT), Rejection Sampling (RS), and Direct Preference Optimization (DPO).", "quantization_scheme": {"all_linear_layers": "4-bit groupwise (group size 32) for weights, 8-bit per-token dynamic for activations", "classification_layer": "8-bit per-channel for weight, 8-bit per-token dynamic for activation", "embedding_layer": "8-bit per-channel quantization"}, "quantization_aware_training_and_lora": "Initializes QAT with BF16 Llama 3.2 SFT checkpoints, performs additional SFT training with QAT. Freezes QAT model backbone and performs SFT with LoRA adaptors (BF16 weights/activations) applied to all transformer layers. Fine-tunes resulting model (backbone and LoRA adaptors) using DPO (referred to as QLoRA).", "spinquant_application": "Applied together with generative post-training quantization (GPTQ). SpinQuant rotation matrix fine-tuning: 100 iterations, 800 samples, sequence-length 2048 from WikiText 2 dataset. GPTQ: 128 samples, same dataset/sequence-length."}, "performance_benchmarks": {"base_pretrained_models_llama_3_2_1b": [{"category": "General", "benchmark": "MMLU", "shots": "5", "metric": "macro_avg/acc_char", "llama_3_2_1b": 32.2}, {"category": "General", "benchmark": "AGIEval English", "shots": "3-5", "metric": "average/acc_char", "llama_3_2_1b": 23.3}, {"category": "General", "benchmark": "ARC-Challenge", "shots": "25", "metric": "acc_char", "llama_3_2_1b": 32.8}, {"category": "Reading comprehension", "benchmark": "SQuAD", "shots": "1", "metric": "em", "llama_3_2_1b": 49.2}, {"category": "Reading comprehension", "benchmark": "QuAC (F1)", "shots": "1", "metric": "f1", "llama_3_2_1b": 37.9}, {"category": "Reading comprehension", "benchmark": "DROP (F1)", "shots": "3", "metric": "f1", "llama_3_2_1b": 28.0}, {"category": "Long Context", "benchmark": "Needle in Haystack", "shots": "0", "metric": "em", "llama_3_2_1b": 96.8}], "instruction_tuned_models_llama_3_2_1b": [{"capability": "General", "benchmark": "MMLU", "shots": "5", "metric": "macro_avg/acc", "llama_3_2_1b_bf16": 49.3, "llama_3_2_1b_vanilla_ptq": 43.3, "llama_3_2_1b_spin_quant": 47.3, "llama_3_2_1b_qlora": 49.0}, {"capability": "Re-writing", "benchmark": "Open-rewrite eval", "shots": "0", "metric": "micro_avg/rougeL", "llama_3_2_1b_bf16": 41.6, "llama_3_2_1b_vanilla_ptq": 39.2, "llama_3_2_1b_spin_quant": 40.9, "llama_3_2_1b_qlora": 41.2}, {"capability": "Summarization", "benchmark": "TLDR9+ (test)", "shots": "1", "metric": "rougeL", "llama_3_2_1b_bf16": 16.8, "llama_3_2_1b_vanilla_ptq": 14.9, "llama_3_2_1b_spin_quant": 16.7, "llama_3_2_1b_qlora": 16.8}, {"capability": "Instruction following", "benchmark": "IFEval", "shots": "0", "metric": "Avg(Prompt/Instruction acc Loose/Strict)", "llama_3_2_1b_bf16": 59.5, "llama_3_2_1b_vanilla_ptq": 51.5, "llama_3_2_1b_spin_quant": 58.4, "llama_3_2_1b_qlora": 55.6}, {"capability": "Math", "benchmark": "GSM8K (CoT)", "shots": "8", "metric": "em_maj1@1", "llama_3_2_1b_bf16": 44.4, "llama_3_2_1b_vanilla_ptq": 33.1, "llama_3_2_1b_spin_quant": 40.6, "llama_3_2_1b_qlora": 46.5}, {"capability": "Math", "benchmark": "MATH (CoT)", "shots": "0", "metric": "final_em", "llama_3_2_1b_bf16": 30.6, "llama_3_2_1b_vanilla_ptq": 20.5, "llama_3_2_1b_spin_quant": 25.3, "llama_3_2_1b_qlora": 31.0}, {"capability": "Reasoning", "benchmark": "ARC-C", "shots": "0", "metric": "acc", "llama_3_2_1b_bf16": 59.4, "llama_3_2_1b_vanilla_ptq": 54.3, "llama_3_2_1b_spin_quant": 57.0, "llama_3_2_1b_qlora": 60.7}, {"capability": "Reasoning", "benchmark": "GPQA", "shots": "0", "metric": "acc", "llama_3_2_1b_bf16": 27.2, "llama_3_2_1b_vanilla_ptq": 25.9, "llama_3_2_1b_spin_quant": 26.3, "llama_3_2_1b_qlora": 25.9}, {"capability": "Reasoning", "benchmark": "Hellaswag", "shots": "0", "metric": "acc", "llama_3_2_1b_bf16": 41.2, "llama_3_2_1b_vanilla_ptq": 38.1, "llama_3_2_1b_spin_quant": 41.3, "llama_3_2_1b_qlora": 41.5}, {"capability": "Tool Use", "benchmark": "BFCL V2", "shots": "0", "metric": "acc", "llama_3_2_1b_bf16": 25.7, "llama_3_2_1b_vanilla_ptq": 14.3, "llama_3_2_1b_spin_quant": 15.9, "llama_3_2_1b_qlora": 23.7}, {"capability": "Tool Use", "benchmark": "Nexus", "shots": "0", "metric": "macro_avg/acc", "llama_3_2_1b_bf16": 13.5, "llama_3_2_1b_vanilla_ptq": 5.2, "llama_3_2_1b_spin_quant": 9.6, "llama_3_2_1b_qlora": 12.5}, {"capability": "Long Context", "benchmark": "InfiniteBench/En.QA", "shots": "0", "metric": "longbook_qa/f1", "llama_3_2_1b_bf16": 20.3}, {"capability": "Long Context", "benchmark": "InfiniteBench/En.MC", "shots": "0", "metric": "longbook_choice/acc", "llama_3_2_1b_bf16": 38.0}, {"capability": "Long Context", "benchmark": "NIH/Multi-needle", "shots": "0", "metric": "recall", "llama_3_2_1b_bf16": 75.0}, {"capability": "Multilingual", "benchmark": "MGSM (CoT)", "shots": "0", "metric": "em", "llama_3_2_1b_bf16": 24.5, "llama_3_2_1b_vanilla_ptq": 13.7, "llama_3_2_1b_spin_quant": 18.2, "llama_3_2_1b_qlora": 24.4}], "multilingual_benchmarks_llama_3_2_1b": [{"category": "General", "benchmark": "MMLU", "metric": "5-shot, macro_avg/acc", "language": "Portuguese", "llama_3_2_1b_bf16": 39.8, "llama_3_2_1b_vanilla_ptq": 34.9, "llama_3_2_1b_spin_quant": 38.9, "llama_3_2_1b_qlora": 40.2}, {"category": "General", "benchmark": "MMLU", "metric": "5-shot, macro_avg/acc", "language": "Spanish", "llama_3_2_1b_bf16": 41.5, "llama_3_2_1b_vanilla_ptq": 36.0, "llama_3_2_1b_spin_quant": 39.8, "llama_3_2_1b_qlora": 41.8}, {"category": "General", "benchmark": "MMLU", "metric": "5-shot, macro_avg/acc", "language": "Italian", "llama_3_2_1b_bf16": 39.8, "llama_3_2_1b_vanilla_ptq": 34.9, "llama_3_2_1b_spin_quant": 38.1, "llama_3_2_1b_qlora": 40.6}, {"category": "General", "benchmark": "MMLU", "metric": "5-shot, macro_avg/acc", "language": "German", "llama_3_2_1b_bf16": 39.2, "llama_3_2_1b_vanilla_ptq": 34.9, "llama_3_2_1b_spin_quant": 37.5, "llama_3_2_1b_qlora": 39.6}, {"category": "General", "benchmark": "MMLU", "metric": "5-shot, macro_avg/acc", "language": "French", "llama_3_2_1b_bf16": 40.5, "llama_3_2_1b_vanilla_ptq": 34.8, "llama_3_2_1b_spin_quant": 39.2, "llama_3_2_1b_qlora": 40.8}, {"category": "General", "benchmark": "MMLU", "metric": "5-shot, macro_avg/acc", "language": "Hindi", "llama_3_2_1b_bf16": 33.5, "llama_3_2_1b_vanilla_ptq": 30.0, "llama_3_2_1b_spin_quant": 32.1, "llama_3_2_1b_qlora": 34.0}, {"category": "General", "benchmark": "MMLU", "metric": "5-shot, macro_avg/acc", "language": "Thai", "llama_3_2_1b_bf16": 34.7, "llama_3_2_1b_vanilla_ptq": 31.2, "llama_3_2_1b_spin_quant": 32.4, "llama_3_2_1b_qlora": 34.9}]}, "memory_requirements": {"inference_time_metrics": {"device": "Android OnePlus 12 device (ARM CPU backend)", "inference_engine": "ExecuTorch", "time_to_first_token_prompt_length": "64", "llama_3_2_1b_bf16": {"decode_tokens_per_sec": 19.2, "time_to_first_token_sec": 1.0, "prefill_tokens_per_sec": 60.3, "model_size_pte_file_mb": 2358, "memory_size_rss_mb": 3185}, "llama_3_2_1b_spinquant": {"decode_tokens_per_sec": "50.2 (2.6x)", "time_to_first_token_sec": "0.3 (-76.9%)", "prefill_tokens_per_sec": "260.5 (4.3x)", "model_size_pte_file_mb": "1083 (-54.1%)", "memory_size_rss_mb": "1921 (-39.7%)"}, "llama_3_2_1b_qlora": {"decode_tokens_per_sec": "45.8 (2.4x)", "time_to_first_token_sec": "0.3 (-76.0%)", "prefill_tokens_per_sec": "252.0 (4.2x)", "model_size_pte_file_mb": "1127 (-52.2%)", "memory_size_rss_mb": "2255 (-29.2%)"}}}}